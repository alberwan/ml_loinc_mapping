{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from hyperopt import fmin, hp, tpe, STATUS_OK, Trials, space_eval\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, classification\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import seaborn as sb\n",
    "import config\n",
    "from LOINCSynonyms import *\n",
    "from DatasetCreationConfigd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category= classification.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 12341\n",
    "N_SPLITS = config.n_splits\n",
    "TUNING_EVALS = config.tuning_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = config.out_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LOINC Synonymn dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loinc_dict(loinc_synonyms):\n",
    "    loinc_dict = defaultdict()\n",
    "    for i in range(loinc_synonyms.shape[0]):\n",
    "        loinc_dict[loinc_synonyms.loc[i, 'LOINC_NUM']] = loinc_synonyms.loc[i, 'LOINC_KEY']\n",
    "    return loinc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    if os.path.exists(filepath + 'datCube.csv'):\n",
    "        dat = pd.read_csv(filepath + 'datCube.csv', sep=',', encoding = \"ISO-8859-1\",\n",
    "            keep_default_na=False, na_values=['', 'NULL', 'N/A', 'N\\A'])\n",
    "    else:\n",
    "        dat = add_string_distance_features()\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_and_filter_data():\n",
    "    dat = get_data()\n",
    "    loinc_synonyms = get_loinc_synonyms()\n",
    "    \n",
    "    feature_col_number = config.num_cuis\n",
    "    X_unfiltered = dat.copy()  \n",
    "    X_unfiltered = X_unfiltered.merge(loinc_synonyms, how='left', left_on=config.loinc_col, right_on='LOINC_NUM') \\\n",
    "    .drop('LOINC_NUM', axis=1)\n",
    "    X_unfiltered = X_unfiltered.set_value(X_unfiltered[X_unfiltered.LOINC_KEY.isnull()].index, \n",
    "        'LOINC_KEY', X_unfiltered.LOINC)\n",
    "    \n",
    "    cumulct_orig_loinc = pd.Series.to_frame(X_unfiltered.groupby(config.loinc_col)[config.count].sum(), \n",
    "    name='CumulCountByOrigLOINC').reset_index()\n",
    "    rowct_orig_loinc = pd.Series.to_frame(X_unfiltered[config.loinc_col].value_counts(), name='RowCtByOrigLOINC')\n",
    "    cumulct_loinc_grp = pd.Series.to_frame(X_unfiltered.groupby('LOINC_KEY')[config.count].sum(),\n",
    "        name='CumulCountByLOINCGrp').reset_index()\n",
    "    rowct_loinc_grps = pd.Series.to_frame(X_unfiltered['LOINC_KEY'].value_counts(), name='RowCtByLOINCGrp')\n",
    "\n",
    "    X_unfiltered = X_unfiltered.merge(cumulct_orig_loinc, how='left', left_on=config.loinc_col, right_on=config.loinc_col)\n",
    "    X_unfiltered = X_unfiltered.merge(cumulct_loinc_grp, how='left', left_on='LOINC_KEY', right_on='LOINC_KEY')\n",
    "    X_unfiltered = X_unfiltered.merge(rowct_orig_loinc, how='left', left_on=config.loinc_col, right_index=True)\n",
    "    X_unfiltered = X_unfiltered.merge(rowct_loinc_grps, how='left', left_on='LOINC_KEY', right_index=True)\n",
    "    \n",
    "    # Recode NaNs as 'MISSING' so encoder can be used\n",
    "    X_unfiltered[[config.loinc_col, config.units, 'TestNameMapJW', 'TestNameMapLV', 'SpecimenMapLV',\n",
    "             'SpecimenMapJW', 'PredictedComponentJW', 'PredictedComponentLV', \n",
    "              'PredictedSystemJW', 'PredictedSystemLV', 'LOINC_KEY']] = X_unfiltered[[config.loinc_col, config.units,\n",
    "              'TestNameMapJW', 'TestNameMapLV', 'SpecimenMapLV',\n",
    "             'SpecimenMapJW', 'PredictedComponentJW', 'PredictedComponentLV', \n",
    "              'PredictedSystemJW', 'PredictedSystemLV', 'LOINC_KEY']].replace(np.nan, 'MISSING')\n",
    "    \n",
    "    cols_to_tranform = [config.units, 'TestNameMapJW', 'TestNameMapLV', 'TestNameMapJW', \n",
    "                'SpecimenMapLV', 'SpecimenMapJW', 'PredictedComponentJW',\n",
    "               'PredictedComponentLV', 'PredictedSystemJW', 'PredictedSystemLV']\n",
    "    \n",
    "    for i in range(feature_col_number):\n",
    "        cols_to_tranform.append('TestCUI{0}'.format(i + 1))\n",
    "        cols_to_tranform.append('SpecCUI{0}'.format(i + 1))\n",
    "        \n",
    "    label_encoder_dict = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "    fitted = X_unfiltered[cols_to_tranform].apply(lambda x: label_encoder_dict[x.name].fit_transform(x))\n",
    "\n",
    "    ### Create separate LOINC encoder than includes codes from both LOINC and LOINC_KEY columns\n",
    "    loinc_coder = preprocessing.LabelEncoder().fit(pd.concat([X_unfiltered[config.loinc_col], X_unfiltered.LOINC_KEY]).unique())\n",
    "\n",
    "    X_unfiltered[cols_to_tranform] = X_unfiltered[cols_to_tranform].apply(lambda x: label_encoder_dict[x.name].transform(x))\n",
    "\n",
    "    X_unfiltered[[config.loinc_col, 'LOINC_KEY']] = X_unfiltered[[config.loinc_col, 'LOINC_KEY']] \\\n",
    "        .apply(lambda x: loinc_coder.transform(x))\n",
    "\n",
    "    ### Filter out rows with missing test name, specimen type, or LOINC code\n",
    "    unknowns = X_unfiltered[(X_unfiltered.CleanedTestName.isnull()) |\n",
    "                           (X_unfiltered.CleanedSpecimen.isnull()) |\n",
    "                           (loinc_coder.inverse_transform(X_unfiltered.LOINC_KEY)== 'MISSING')]\n",
    "\n",
    "    X_labeled = X_unfiltered.iloc[~X_unfiltered.index.isin(unknowns.index)]\n",
    "    \n",
    "    ### Calculate Number of Sites per LOINC code and per LOINC_KEY\n",
    "    site_cts = X_labeled.copy()\n",
    "    loinc_site_cts = site_cts.groupby(config.loinc_col)[config.site].nunique()\n",
    "    joiner = pd.DataFrame(loinc_site_cts.values, index=loinc_site_cts.index, columns=['SiteCountByOrigLOINC'])\n",
    "    site_cts = site_cts.merge(joiner, how='left', left_on=config.loinc_col, right_index=True)\n",
    "    loinc_grp_site_cts = site_cts.groupby('LOINC_KEY')[config.site].nunique()\n",
    "    joiner2 = pd.DataFrame(loinc_grp_site_cts.values, index=loinc_grp_site_cts.index, columns=['SiteCountByLOINCGrp'])\n",
    "    site_cts = site_cts.merge(joiner2, how='left', left_on='LOINC_KEY', right_index=True)\n",
    "    \n",
    "    ### Filter out rows where LOINC group occurs at only one site\n",
    "    unknowns = pd.concat([unknowns, site_cts[site_cts.SiteCountByLOINCGrp <= config.min_sites_per_loinc_key] \\\n",
    "        .drop(['SiteCountByOrigLOINC', 'SiteCountByLOINCGrp'], axis=1)])\n",
    "    \n",
    "    X_labeled = X_labeled.iloc[~X_labeled.index.isin(unknowns.index)]\n",
    "    \n",
    "    ## Filter out rows where cumulative number of test instances is <= 9 for LOINC group or\n",
    "    ## where row count per LOINC group is < 2\n",
    "    unknowns = pd.concat([unknowns, X_labeled[(X_labeled.CumulCountByLOINCGrp <= config.min_tests_per_loinc_group) |\n",
    "        (X_labeled.RowCtByLOINCGrp < config.min_row_count_per_loinc_group)]])\n",
    "    \n",
    "    X_labeled = X_labeled.iloc[~X_labeled.index.isin(unknowns.index)].reset_index(drop=True)\n",
    "    \n",
    "    return label_encoder_dict, loinc_coder, X_unfiltered, X_labeled, unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agnostic site-splitting (does not ensure that test labels are present in training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_site_splits():\n",
    "    n_splits = N_SPLITS\n",
    "    N_rows = X0.shape[0]\n",
    "    site_list = X0[config.site].unique()\n",
    "    site_list.sort()\n",
    "\n",
    "    site_list = shuffle(site_list, random_state=seed)\n",
    "    working_list = site_list.copy()\n",
    "\n",
    "    site_splits = []\n",
    "    for i in range(n_splits):\n",
    "        site_ct = 0\n",
    "        test_sites = []\n",
    "        while site_ct < len(working_list) and (len(test_sites) == 0 or\n",
    "            X0[X0[config.site].isin(test_sites)].shape[0] / N_rows < ((1 / n_splits) - 0.005)):\n",
    "            test_sites.append(working_list[site_ct])\n",
    "            site_ct = site_ct + 1\n",
    "        if (i < n_splits - 1):\n",
    "            site_splits.append(test_sites)\n",
    "            working_list = working_list[site_ct :]\n",
    "    site_splits.append(working_list)\n",
    "    \n",
    "    return site_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_indices():\n",
    "    test_ind = []\n",
    "    tune_train_ind = []\n",
    "    tune_test_ind = []\n",
    "    \n",
    "    site_splits = get_site_splits()\n",
    "\n",
    "    for j in range(len(site_splits)):\n",
    "        np.random.seed(seed=seed)\n",
    "        test_ind.append(X0[X0[config.site].isin(site_splits[j])].index)\n",
    "        tune_test_ind.append(np.random.choice(test_ind[j], replace=False, size=int(len(test_ind[j]) * 0.1666666)))\n",
    "        tune_train_ind.append(test_ind[j][~test_ind[j].isin(tune_test_ind[j])])\n",
    "    return test_ind, tune_train_ind, tune_test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder_dict, loinc_coder, X_unfiltered, X_labeled, unknowns = transform_and_filter_data()\n",
    "\n",
    "## Select columns for labeled and unlabeled/unknown datasets\n",
    "data_cols = [config.site, config.units, config.mean_col, config.min_col, config.max_col, \n",
    "   config.perc_5, config.perc_25, config.median_col, config.perc_75,\n",
    "   config.perc_95, config.loinc_col, 'FreqPercent', 'TestNameMapLV',\n",
    "   'TestNameMapJW', 'SpecimenMapLV', 'SpecimenMapJW',\n",
    "   'ComponentMatchDistJW', 'ComponentMatchDistLV', 'PredictedComponentJW',\n",
    "   'PredictedComponentLV', 'PredictedSystemJW', 'PredictedSystemLV',\n",
    "   'SystemMatchDistJW', 'SystemMatchDistLV', 'LOINC_KEY']\n",
    "for i in range(config.num_cuis):\n",
    "    data_cols.append('SpecCUI{0}'.format(i + 1))\n",
    "    data_cols.append('TestCUI{0}'.format(i + 1))\n",
    "\n",
    "X0 = X_labeled[data_cols]\n",
    "\n",
    "data_cols.remove('LOINC_KEY')\n",
    "    \n",
    "unknowns_analysis = unknowns[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get indices for hyperparameter tuning so that the test set data is not used during evaluating hyperparameters\n",
    "test_ind, tune_train_ind, tune_test_ind = get_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### GET RID OF THIS FOR FINAL VERSION ###\n",
    "site_splits = [[358], [402], [405], [436], [437]]\n",
    "X0 = X0[X0.Sta3n.isin(np.concatenate(site_splits))]\n",
    "unknowns_analysis = unknowns_analysis[unknowns_analysis.Sta3n.isin(np.concatenate(site_splits))]\n",
    "### END OF CODE DELETION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary for hyperparameters for hyperopt package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacedict = {'criterion': ['gini', 'entropy'],\n",
    "           'max_features': np.arange(2, (X0.shape[1] - 3), 2),\n",
    "           'max_depth': np.arange(5, 35, 5),\n",
    "           'min_samples_split': np.arange(2, 20, 2),\n",
    "           'n_estimators': np.array([10, 20, 50, 75, 100, 125, 150, 175, 200])}\n",
    "\n",
    "space4rf = {key: hp.choice(key, spacedict[key]) for key in spacedict.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User hyperopt package to tune RF hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_f(rf_params):\n",
    "    global rf_best\n",
    "    f1 = rf_hyperopt_train_test(rf_params)\n",
    "    if f1 > rf_best:\n",
    "        rf_best = f1\n",
    "        print('new best: ', rf_best, rf_params)\n",
    "    if rf_trials.trials[-1]['tid'] % 5 == 0:\n",
    "        pickle.dump(rf_trials, open(filepath + 'rf_tuning_trials_final', 'wb'))\n",
    "    return {'loss': -f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rf_trials():\n",
    "    rf_best = 0\n",
    "    try:\n",
    "        rf_trials = pickle.load(open(filepath + 'rf_tuning_trials_final', 'rb'))\n",
    "        if rf_trials.trials[len(rf_trials) - 1]['result']['status'] == 'new':\n",
    "            rf_trials.trials.pop()\n",
    "        for i in range(len(rf_trials.trials)):\n",
    "            if (rf_trials.trials[i]['result']['status'] == 'ok' and\n",
    "                -rf_trials.trials[i]['result']['loss'] > rf_best):\n",
    "                    rf_best = -rf_trials.trials[i]['result']['loss']\n",
    "    except FileNotFoundError:\n",
    "        rf_trials = Trials()\n",
    "        \n",
    "    while len(rf_trials) < TUNING_EVALS:\n",
    "        rf_best = fmin(rf_f, space4rf, algo=tpe.suggest, max_evals=TUNING_EVALS, \n",
    "               trials=rf_trials, rstate=np.random.RandomState(seed))\n",
    "        \n",
    "    return rf_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_trials = get_rf_trials()\n",
    "\n",
    "rf_final_parms = dict()\n",
    "\n",
    "for key in rf_trials.best_trial['misc']['vals'].keys():\n",
    "    rf_final_parms[key] = spacedict[key][rf_trials.best_trial['misc']['vals'][key][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User hyperopt package to tune RF hyperparameters for OVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ovr_hyperopt_train_test(ovr_params):\n",
    "    score_ovr = []\n",
    "    if ovr_trials.trials[-1]['tid'] % 5 == 0:\n",
    "        print('Trial: ', ovr_trials.trials[-1]['tid'])\n",
    "    for i in range(N_SPLITS):\n",
    "        ovr = OneVsRestClassifier(RandomForestClassifier(random_state=seed, n_jobs=-1, **ovr_params))\n",
    "        X_train = X0.iloc[np.concatenate(tune_train_ind[:i] + tune_train_ind[i + 1:])].drop([config.site, config.loinc_col], axis=1)\n",
    "        y_train = X_train.pop('LOINC_KEY')\n",
    "        X_test = X0.iloc[np.concatenate(tune_test_ind[:i] + tune_test_ind[i + 1:])].drop([config.site, config.loinc_col], axis=1)\n",
    "        y_test = X_test.pop('LOINC_KEY')\n",
    "        ovr.fit(X_train, y_train)\n",
    "        y_preds = ovr.predict(X_test)\n",
    "        score_ovr.append(f1_score(y_test, y_preds, labels=ovr.classes_, average='weighted'))\n",
    "        del ovr\n",
    "    return np.mean(score_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ovr_f(ovr_params):\n",
    "    global ovr_best\n",
    "    f1 = ovr_hyperopt_train_test(ovr_params)\n",
    "    if f1 > ovr_best:\n",
    "        ovr_best = f1\n",
    "        print('new best: ', ovr_best, ovr_params)\n",
    "    if ovr_trials.trials[-1]['tid'] % 5 == 0:\n",
    "        pickle.dump(ovr_trials, open(filepath + 'ovr_tuning_trials_final', 'wb'))\n",
    "    return {'loss': -f1, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ovr_trials():\n",
    "    ovr_best = 0\n",
    "    try:\n",
    "        ovr_trials = pickle.load(open(filepath + 'ovr_tuning_trials_final', 'rb'))\n",
    "        if ovr_trials.trials[len(ovr_trials) - 1]['result']['status'] == 'new':\n",
    "            ovr_trials.trials.pop()\n",
    "        for i in range(len(ovr_trials.trials)):\n",
    "            if (ovr_trials.trials[i]['result']['status'] == 'ok' and\n",
    "                -ovr_trials.trials[i]['result']['loss'] > ovr_best):\n",
    "                    ovr_best = -ovr_trials.trials[i]['result']['loss']\n",
    "    except FileNotFoundError:\n",
    "        ovr_trials = Trials()\n",
    "        \n",
    "    while len(ovr_trials) < TUNING_EVALS:\n",
    "        ovr_best = fmin(ovr_f, space4rf, algo=tpe.suggest, max_evals=TUNING_EVALS, \n",
    "            trials=ovr_trials, rstate=np.random.RandomState(seed))\n",
    "    \n",
    "    return ovr_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovr_trials = get_ovr_trials()\n",
    "\n",
    "ovr_final_parms = dict()\n",
    "\n",
    "for key in ovr_trials.best_trial['misc']['vals'].keys():\n",
    "    ovr_final_parms[key] = spacedict[key][ovr_trials.best_trial['misc']['vals'][key][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get performance estimates for models after hyperparameters tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_cv(X0, unknowns_analysis):\n",
    "    metric_names = ['Accuracy', 'F1 weighted', 'F1 macro', 'F1 micro']\n",
    "    output_names = ['accuracy', 'f1_weighted', 'f1_macro', 'f1_micro']\n",
    "\n",
    "    ovr_accuracy = np.zeros(N_SPLITS)\n",
    "    ovr_f1_weighted = np.zeros(N_SPLITS)\n",
    "    ovr_f1_macro = np.zeros(N_SPLITS)\n",
    "    ovr_f1_micro = np.zeros(N_SPLITS)\n",
    "    ovr_preds = []\n",
    "    ovr_unk_preds = []\n",
    "\n",
    "    rf_accuracy = np.zeros(N_SPLITS)\n",
    "    rf_f1_weighted = np.zeros(N_SPLITS)\n",
    "    rf_f1_macro = np.zeros(N_SPLITS)\n",
    "    rf_f1_micro = np.zeros(N_SPLITS)\n",
    "    rf_preds = []\n",
    "    rf_unk_preds = []\n",
    "\n",
    "    for i in range(N_SPLITS):\n",
    "        print(\"RF CV: \", i + 1)\n",
    "        X_train = X0[~X0[config.site].isin(site_splits[i])].drop([config.site, config.loinc_col], axis=1)\n",
    "        y_train = X_train.pop('LOINC_KEY')\n",
    "        X_test = X0[X0[config.site].isin(site_splits[i])].drop([config.site, config.loinc_col], axis=1)\n",
    "        y_test = X_test.pop('LOINC_KEY')\n",
    "        X_unk_test = unknowns_analysis[unknowns_analysis[config.site].isin(site_splits[i])].drop([config.site, \n",
    "            config.loinc_col], axis=1)\n",
    "        rf = RandomForestClassifier(criterion=rf_final_parms['criterion'],\n",
    "            max_features=rf_final_parms['max_features'],\n",
    "            max_depth=rf_final_parms['max_depth'],\n",
    "            min_samples_split=rf_final_parms['min_samples_split'],\n",
    "            n_estimators=rf_final_parms['n_estimators'],\n",
    "            n_jobs=-1, random_state=seed)\n",
    "\n",
    "        rf.fit(X_train, y_train)      \n",
    "        y_pred = rf.predict(X_test)\n",
    "        rf_preds.append(y_pred)\n",
    "        y_unk_pred = rf.predict(X_unk_test)\n",
    "        rf_unk_preds.append(y_unk_pred)\n",
    "\n",
    "        rf_accuracy[i] = accuracy_score(y_test, y_pred)\n",
    "        rf_f1_weighted[i] = f1_score(y_test, y_pred, labels=rf.classes_, average='weighted')\n",
    "        rf_f1_macro[i] = f1_score(y_test, y_pred, labels=rf.classes_, average='macro')\n",
    "        rf_f1_micro[i] = f1_score(y_test, y_pred, labels=rf.classes_, average='micro')\n",
    "\n",
    "        del rf\n",
    "\n",
    "        print(\"OVR CV: \", i + 1)\n",
    "        ovr = OneVsRestClassifier(RandomForestClassifier(criterion=ovr_final_parms['criterion'],\n",
    "            max_features=ovr_final_parms['max_features'],\n",
    "            max_depth=ovr_final_parms['max_depth'],\n",
    "            min_samples_split=ovr_final_parms['min_samples_split'],\n",
    "            n_estimators=ovr_final_parms['n_estimators'],\n",
    "            n_jobs=-1, random_state=seed), n_jobs= -1)    \n",
    "\n",
    "        ovr.fit(X_train, y_train)      \n",
    "        y_pred = ovr.predict(X_test)\n",
    "        ovr_preds.append(y_pred)\n",
    "        y_unk_pred = ovr.predict(X_unk_test)\n",
    "        ovr_unk_preds.append(y_unk_pred)\n",
    "\n",
    "        ovr_accuracy[i] = accuracy_score(y_test, y_pred)\n",
    "        ovr_f1_weighted[i] = f1_score(y_test, y_pred, labels=ovr.classes_, average='weighted')\n",
    "        ovr_f1_macro[i] = f1_score(y_test, y_pred, labels=ovr.classes_, average='macro')\n",
    "        ovr_f1_micro[i] = f1_score(y_test, y_pred, labels=ovr.classes_, average='micro')\n",
    "\n",
    "        del ovr\n",
    "    \n",
    "    for i in range(len(ovr_preds)):\n",
    "        X_intermed = X0[X0[config.site].isin(site_splits[i])].copy()\n",
    "        X_intermed['RFCVPredLOINC'] = rf_preds[i]\n",
    "        X_intermed['RFCVLOINC'] = np.where(~(X_intermed[config.loinc_col] == X_intermed['LOINC_KEY']) &\n",
    "             (X_intermed['LOINC_KEY'] == X_intermed['RFCVPredLOINC']), \n",
    "                X_intermed[config.loinc_col], X_intermed['RFCVPredLOINC'])\n",
    "        X_intermed['OVRCVPredLOINC'] = ovr_preds[i]\n",
    "        X_intermed['OVRCVLOINC'] = np.where(~(X_intermed[config.loinc_col] == X_intermed['LOINC_KEY']) &\n",
    "             (X_intermed['LOINC_KEY'] == X_intermed['OVRCVPredLOINC']), \n",
    "                X_intermed[config.loinc_col], X_intermed['OVRCVPredLOINC'])\n",
    "\n",
    "        X_unk_intermed = unknowns_analysis[unknowns_analysis[config.site].isin(site_splits[i])].copy()\n",
    "        X_unk_intermed['RFCVPredLOINC'] = rf_unk_preds[i]\n",
    "        X_unk_intermed['OVRCVPredLOINC'] = ovr_unk_preds[i]\n",
    "        if i == 0:\n",
    "            X_cvs = X_intermed\n",
    "            X_unk_cvs = X_unk_intermed\n",
    "        else:\n",
    "            X_cvs = pd.concat([X_cvs, X_intermed])\n",
    "            X_unk_cvs = pd.concat([X_unk_cvs, X_unk_intermed])\n",
    "        \n",
    "    X_cvs = X_cvs.sort_index()\n",
    "    X_unk_cvs = X_unk_cvs.sort_index()\n",
    "\n",
    "    cvs = np.zeros((len(output_names), 2))\n",
    "    for i in range(len(output_names)):\n",
    "        cvs[i][0] = vars()['rf_' + output_names[i]].mean()\n",
    "        cvs[i][1] = vars()['ovr_' + output_names[i]].mean()\n",
    "\n",
    "    metrics = pd.DataFrame(data=cvs, index=metric_names, columns=['RF', 'OVR'])\n",
    "    \n",
    "    return X_cvs, X_unk_cvs, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF CV:  1\n",
      "OVR CV:  1\n",
      "RF CV:  2\n",
      "OVR CV:  2\n",
      "RF CV:  3\n",
      "OVR CV:  3\n",
      "RF CV:  4\n",
      "OVR CV:  4\n",
      "RF CV:  5\n",
      "OVR CV:  5\n"
     ]
    }
   ],
   "source": [
    "if config.run_cv == 'Y':\n",
    "    X_cvs, X_unk_cvs, cv_metrics = run_cv(X0, unknowns_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to full labeled dataset, make predictions, then make predictions on unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_overall = X0.drop([config.site, config.loinc_col, 'LOINC_KEY'], axis=1)\n",
    "y_overall = X0['LOINC_KEY']\n",
    "\n",
    "rf_final = RandomForestClassifier(criterion=rf_final_parms['criterion'],\n",
    "    max_features=rf_final_parms['max_features'],\n",
    "    max_depth=rf_final_parms['max_depth'],\n",
    "    min_samples_split=rf_final_parms['min_samples_split'],\n",
    "    n_estimators=rf_final_parms['n_estimators'],\n",
    "    n_jobs=-1, random_state=seed)\n",
    "\n",
    "rf_final.fit(X_overall, y_overall)\n",
    "rf_preds = rf_final.predict(X_overall)\n",
    "rf_preds_frame = pd.DataFrame(rf_preds, index=X0.index, columns=['RFFullModelPredLOINCKey'])\n",
    "\n",
    "ovr_final = OneVsRestClassifier(RandomForestClassifier(criterion=ovr_final_parms['criterion'],\n",
    "    max_features=ovr_final_parms['max_features'],\n",
    "    max_depth=ovr_final_parms['max_depth'],\n",
    "    min_samples_split=ovr_final_parms['min_samples_split'],\n",
    "    n_estimators=ovr_final_parms['n_estimators'],\n",
    "    n_jobs=-1, random_state=seed), n_jobs= -1)\n",
    "\n",
    "ovr_final.fit(X_overall, y_overall)\n",
    "ovr_preds = ovr_final.predict(X_overall)\n",
    "ovr_preds_frame = pd.DataFrame(ovr_preds, index=X0.index, columns=['OVRFullModelPredLOINCKey'])\n",
    "\n",
    "X_unk_overall = unknowns_analysis.drop([config.site, config.loinc_col], axis=1)\n",
    "\n",
    "rf_unknown_preds = rf_final.predict(X_unk_overall)\n",
    "rf_unk_preds_frame = pd.DataFrame(rf_unknown_preds, index=X_unk_overall.index, columns=['RFFullModelPredLOINCKey'])\n",
    "\n",
    "ovr_unknown_preds = ovr_final.predict(X_unk_overall)\n",
    "ovr_unk_preds_frame = pd.DataFrame(ovr_unknown_preds, index=X_unk_overall.index, columns=['OVRFullModelPredLOINCKey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if config.run_cv == 'Y':\n",
    "    X0 = X_cvs.copy()\n",
    "    unknowns_analysis = X_unk_cvs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_final = X0.merge(rf_preds_frame, how='inner', left_index=True, right_index=True) \\\n",
    "    .merge(ovr_preds_frame, how='inner', left_index=True, right_index=True)\n",
    "unknowns_final = unknowns_analysis.merge(rf_unk_preds_frame, how='inner', left_index=True, right_index=True) \\\n",
    "    .merge(ovr_unk_preds_frame, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If original LOINC code is a member of the predicted LOINC_KEY, retain the original LOINC code as the \n",
    "## final label\n",
    "X_final['RFFullModelFinalLOINCKey'] = np.where(~(X_final[config.loinc_col] == X_final['LOINC_KEY']) &\n",
    "         (X_final['LOINC_KEY'] == X_final['RFFullModelPredLOINCKey']), \n",
    "            X_final[config.loinc_col], X_final['RFFullModelPredLOINCKey'])\n",
    "X_final['OVRFullModelFinalLOINCKey'] = np.where(~(X_final[config.loinc_col] == X_final['LOINC_KEY']) &\n",
    "         (X_final['LOINC_KEY'] == X_final['OVRFullModelPredLOINCKey']), \n",
    "            X_final[config.loinc_col], X_final['OVRFullModelPredLOINCKey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_transform = X_final.columns[X_final.columns.isin(label_encoder_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Inverse transforms factor variables back to original data\n",
    "X_final[cols_to_transform] = X_final[cols_to_transform] \\\n",
    "    .apply(lambda x: label_encoder_dict[x.name].inverse_transform(x))\n",
    "unknowns_final[cols_to_transform] = unknowns_final[cols_to_transform] \\\n",
    "    .apply(lambda x: label_encoder_dict[x.name].inverse_transform(x))\n",
    "\n",
    "## Inverse transforms factor-converted LOINC codes back to actual LOINC codes\n",
    "if config.run_cv == 'Y':\n",
    "    X_final[['RFCVPredLOINC', 'RFCVLOINC', 'OVRCVPredLOINC', 'OVRCVLOINC']] = loinc_coder \\\n",
    "        .inverse_transform(X_final[['RFCVPredLOINC', 'RFCVLOINC', 'OVRCVPredLOINC', 'OVRCVLOINC']])\n",
    "    unknowns_final[['RFCVPredLOINC', 'OVRCVPredLOINC']] = loinc_coder \\\n",
    "        .inverse_transform(unknowns_final[['RFCVPredLOINC', 'OVRCVPredLOINC']])\n",
    "X_final[[config.loinc_col, 'LOINC_KEY', 'RFFullModelPredLOINCKey', 'OVRFullModelPredLOINCKey',\n",
    "        'RFFullModelFinalLOINCKey', 'OVRFullModelFinalLOINCKey']] = loinc_coder \\\n",
    "    .inverse_transform(X_final[[config.loinc_col, 'LOINC_KEY', 'RFFullModelPredLOINCKey', 'OVRFullModelPredLOINCKey',\n",
    "        'RFFullModelFinalLOINCKey', 'OVRFullModelFinalLOINCKey']])\n",
    "unknowns_final[[config.loinc_col, 'RFFullModelPredLOINCKey', 'OVRFullModelPredLOINCKey']] = loinc_coder \\\n",
    "    .inverse_transform(unknowns_final[[config.loinc_col, 'RFFullModelPredLOINCKey', 'OVRFullModelPredLOINCKey']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_final = X_labeled[[config.site, config.test_col, 'CleanedTestName', config.spec_col, 'CleanedSpecimen', \n",
    "    config.count, config.loinc_col, 'LOINC_KEY']] \\\n",
    "    .merge(X_final.drop([config.site, config.loinc_col, 'LOINC_KEY'], axis=1), \n",
    "           how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "unknowns_final = unknowns[[config.site, config.test_col, 'CleanedTestName', config.spec_col, 'CleanedSpecimen',\n",
    "    config.count, config.loinc_col, 'LOINC_KEY']] \\\n",
    "    .merge(unknowns_final.drop([config.site, config.loinc_col], axis=1),\n",
    "          how='inner', left_index=True, right_index=True)\n",
    "\n",
    "X_final.to_csv(filepath + 'labeled_data_predictions.csv')\n",
    "unknowns_final.to_csv(filepath + 'unlabeled_data_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
